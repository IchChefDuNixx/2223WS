Sheet notes ss22

URL:
Chapter 0
7-8 SV vs USV
9 Techniques
16 Properties of a similarity function
21,22 Hamming Distance, Edit Distance (note just the existence of them)
26 K-mean algorithm
31 K-mean strengths
32 rule of thumb k=sqrt(n/2)

Chapter 1
5,6 ideas for loss function
9,10 Elbow method using distortion, basic idea
12,13 Silhouette score formula, low/high meaning
24,30 Linkage
29 Understanding dendrogram (highest vertical distance)
32 Agnes vs Diana
33 K-Mean vs H-Clustering

Chapter 2
Idea: write down the method signature of certain classes (e.g. DBSCAN(X,eps=default_value,minpts=default_value) etc.)
6 DBSCAN Overviews
8,15 types of points
12 algorithm
26 epsilon elbow method
31 comparison

Chapter 3
4-8 examples for use-cases
12 Label encoding
13 One hot encoding
14,15 what to do with data
17,20,22 Scaler functions

Chapter 4
8 Curse of Dimensionality
15 Benefits of Dimensionality Reduction
22 Usage of PCA
25 projection
27 mafs
30 visualization
31 steps for pca
32 more mafs
33,34 cov
35,36 number of pcs

Chapter 5
8 PCA simplified
16 how to project on PC?
17 total variation formula
18,19 more cov (19 real eigenvalues, diagonalization)
20,21 cov properties

Chapter 6
9 Eigenface algorithm
11 PCA vs SNE
14 SNE
17-23 t-SNE algorithm

Chapter 7
Autoencoder tasks = {compress-decompress, denoise, anomaly detection}
13,14 Visualizations
keras code?

Chapter 8
4,8 diagram
9,11 RL characteristics
24 Discount Factor
25 Markov Decision Process
27 Qt(a)


Chapter 9


Chapter 10


Chapter 11


Chapter 12 (Recap)



Mock exam missing knowledge
5a layer size formulas
6b MDP
6c Q-Learning



Stochastics:
BSOM:
part 3
(diagram of a rectangle Omega with subsets A,B + page 4 def 3)
sigma Algebra (collection of subsets in discr.) -> discrete=Powerset(Omega); abs. cont.=Borelset(Omega)
discrete=countably many outcome; abs. cont.=uncountably many outcomes; mixed=at least 1 discrete point and 1 continous part
discrete pmf = sum of single probabilities within set
abs. cont. pdf = integral of f(x) over set (f(x) = distribution like U,Exp,N)
part 5
definition of a (discrete) probability space
part 6
Hypergeometric: H(N,Kn,n)
-P({k1,k2,k3})=(N1 choose k1 * N2 choose k2 * N3 choose k3)/(N choose n)
-2 class: P({k})=((N1 choose k1) * (N-N1 choose n-k))/(N choose n)
part 9
change of integral interval with set
part 11
Bernoulli: Bin(1,p)
part 12
determine the cdf/how to take the integral
part 13
independence of random variables, joint cdf
page 12 def 13
page 13 ex 14, prop 15
part 14
formula for manually calculating the expectation
part 15
properties of the expectation
part 16
formula for manually calculating the variance
properties of the variance 
part 18 more properties of var and std
proofs



definition of a (discrete) probability space
5 remark 4 rewritten events
5 ex 8 |Pow(Omega)| = 2^|Omega|
5 def 9 sigma additivity (p of disjoint union = sum of p of disjoint events) ?
6 prop 10 i-v
6 prop 2 i,iii proof
8 def 1 + bayes
9 remark 4 q(w)
9 def 5,6
9 prop 8 i,ii + P(A)P(B|A) = P(B)P(A|B) if Ai,Bi > 0
10 def 2 x = X(w) realization
11 def 8,12 prop 10 indentically distributed random variables
12 def 13,13 prop 15 independence of random variables
16 Figure 5.1 (what is a contingency table)
17 def 2
17 prop 4
/*Big table for all distributions*/
	Bernoulli: B(1,p) single binomial trial with p=chance of sucess, E(X)=p, Var(X)=p*(1-p)
	Binomial: B(n,p), n=trials,p=chance of success, E(X)=np, Var(X)=np(1-p)
	-P({X=k})=(n choose k)* p^k * (1-p)^(n-k)
	Multinomial: M(n,p0...pm), same as having m Binomials with n trials each but different p, P(A=x,B=y,C=z)=((x+y+z)!/(x!*y!*z!))*(pa^x)*(pb^y)*(pc^z)
	E(Xi) = npi, Var(Xi) = n*pi*(1-pi)
	Hypergeometric: H(N,K,n) urn model without replacement, n,k <= N, E(X) = n* K/N, Var(X) = n* K/N * N-K / N * N-n / N-1
	P(X=k) = (K choose k)*(N-K choose n-k)/(N choose n)
	H -> B if 20 prop 11 holds (p = K/N for large enough N)
	Poisson: Poi(lambda) E(X) = lambda, Var(X) = lambda, P(X=k) = exp(-lambda) * lambda^k / k!
	poisson limit theorem: B -> Poi if 20 prop 13 holds (lambda = n*p for big enough n)
	used for radioactive decay or calls per hour in a call center
	Geometric: Geo(p), E(X) = 1/p Var(X) = (1-p)/p², discrete exponential, used for waiting time
	P(X=k)=p*(1-p)^(k-1)
	discrete uniform: P(X=k) = 1/n, E(X)=(a+b)/2, Var(X)=(n²-1)/12

	continuous Uniform: U(a,b)
	Exponential: Exp(lambda)
	Normal: N(mu,sigma^2)
*still discrete here
24 def 1 E(X) = sum(outcome * respective probability)
24 prop 5 ii proof
25 def 9,remark 10, 26 prop 12 i,ii proof
27 prop 15 chebyshev
28 def 18 sample variance correction factor
*now continuous
31 remark 6 proof
32 def 7 E(X) = int_R (x*f(x)) dx, Var(X) = int_R (x-E(X))^2 dx
33 def 6 independence
34 def 1 cdf
34 prop 5 get cdf by integrating pdf
35 cdf of Exp(l) = 1-exp(-lx) # maybe add more cont. cdfs
37 ex 10 quantile for Exp(l)
37 def 12 median m(X) -> p = 0.5
38 prop 15 |E(X) - m(X)| = std(X)
41 lemma 3 proofs for sample E(XBarn) and Var(XBarn)
43 prop 7 SLLN: XBarn lim->a.s. E(X1)






extras:
*determine rules for interchanging sums and unions or sums and products etc
find out the max/min of multiple variables (2.1b)
log rules!
poisson limit theorem. B(n,p) -> P(n*p)
	H(N,K,n) -> B(K/N)
definition of E and Var for discrete and continous caseshttps://proofwiki.org/wiki/Variance_of_Continuous_Uniform_Distribution
integral over x^2 * f(x) dx - E(X)^2
derivation and integration rules
how to deal with |X| (eg 2 different cases or P({-a < X < a}))
diagrams of all, just regular or just weird distros
ex 6.1 min(a,b) > x <=> (a > x) ^ (b > x)
population variance/stdev = n
sample variance/stdev = n-1
7.3
note down Z score of common values (1,2,3) + Z score given confidence (90%,95%,99%)
CI for mu of normal dist: xBar +- q_1-alpha * sigma / sqrt n
CI for mu with unknown var of normal dist: xBar +- t(n-1)_1-alpha * E(sigma) / sqrt n
CI for var of normal dist with unknown mu:
[Sn² * (n-1) / KAI²(n-1)_1-alpha/2 ; Sn² * (n-1) / KAI²(n-1)_alpha/2]
note down how much % 1,2,3 * std covers (68.269, 95.450, 99.730)
ask about 33 prop 9
ask about Limit Theorems




SVL:
// Nici's notes on what to remember
ch2 p11 types of attributes
p19 types of data sets
p32 preprocessing
ch3 knn
p4 genereal properties
p5 pseudocode nn/knn
ch4 bayes formula
do examples, weather/email ex from tilly (spam)
ch5 regression
ch6 p37 infogain
ch6.2 random forest, model stacking, bagging, boosting, pruning, ID3 algorithm
ch7 p41 p(y|x) = sigma * sigma-
perceptron?
ch8
ch9 confusion matrix, performance estimation, roc curve
ch10 adaboost p9

// own notes
Applications: Computer Vision, Speech Processing (making decisions)
1/13 direct or indirect feedback/reward
1/27 Categorization of supervised learning problems:
	❑ If Y is qualitative/discrete, we refer to the problem as Classification problem.
	❑ If Y is quantitative/continuous, we refer to the problem as Regression problem.
1/28 Modelling Error, Sampling Error, Optimization/Generalization Error
1/31 LMS
1/37 Bias-Variance tradeoff
1/38 no free lunch theorem
2/11 types of attributes
2/15 types of attributes
2/32 preprocessing techniques
3/4 general properties
3/13 runtime complexity of n
3/20 knn challenges
4/1 basic bayes
4/7 analogy to ML
4/10 independence
4/22 
	(2/9)*(3/9)*(3/9)*(3/9)*(9/14) = 0.0053
	(3/5)*(1/5)*(4/5)*(3/5)*(5/14) = 0.0206
	yes/total -> 20,5%
	no/total -> 79,5%
5/9 b1,b0
5/11 r² = sum(f(xi)-ȳ)² / sum(yi-ȳ)²
5/19 polynomial regression -> multiple linear regression
6/19 when to use decision trees
6/28 impurity reduction
ID3 decision tree algorithm, split based on entropy
CART algorithm = ID3 with only binary splittings
6b/30-32 Pruning techniques
6b/39,40 Ensemble learning techniques
6b/46 Random Forest properties
7/19 weight update: wi += mu * error * xi
7/39 sigmoid function
7/41 double sigmoid
8/6,7,8 activation functions
8/13 Learning Rate
9/12 F Score, F1=2(Prec*Reca / Prec + Reca)
9/15 roc curve, TPR/FPR
9/29 Performance estimation summary
10/8,9 adaboost formulas






SQL concepts:
-DDL/DML
-create/drop/alter table
-int/float/decimal/(var)char/bit/date/time
-constraint c check
-insert/update/delete
-SFW block
-cast
-relational algebra (projection, selection, cross product, join, renaming, difference, intersection, union)
-Aggregates
-group by/having/order by
-top-k
-named queries (with t as (...))
-recursion
-division
-integrity constraints
-inline triggers
-standard triggers (inserted, deleted)
-views
-access rights
-variables
-functions
-procedures
-if/else
-while loop
-cursor

Atomicity
Consistency
Isolation
Durability

Dirty Read
Unrepeatable Read
Lost Update
Phantom Problem

